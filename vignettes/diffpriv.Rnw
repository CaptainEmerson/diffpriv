%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{diffpriv}

\documentclass[twoside,11pt]{article}

% Any additional packages needed should be included after jmlr2e.
% Note that jmlr2e.sty includes epsfig, amssymb, natbib and graphicx,
% and defines many common macros, such as 'proof' and 'example'.
%
% It also sets the bibliographystyle to plainnat; for more information on
% natbib citation styles, see the natbib documentation, a copy of which
% is archived at http://www.jmlr.org/format/natbib.pdf

\usepackage{jmlr2e}
\usepackage{xspace}

% Definitions of handy macros can go here

\newcommand{\pckPlain}{diffpriv\xspace}
\newcommand{\pck}{\textsf{\pckPlain}\xspace}
\newcommand{\R}{\textsf{R}\xspace}
\newcommand{\term}[1]{\emph{#1}\xspace}
\newcommand{\cf}{\emph{cf.}\xspace}
\newcommand{\eg}{\emph{e.g.},\xspace}
\newcommand{\ie}{\emph{i.e.},\xspace}
\newcommand{\cB}{\ensuremath{\mathcal{B}}\xspace}
\newcommand{\cD}{\ensuremath{\mathcal{D}}\xspace}
\newcommand{\cR}{\ensuremath{\mathcal{R}}\xspace}
\newcommand{\reals}{\ensuremath{\mathbb{R}}\xspace}
\renewcommand{\v}[1]{\ensuremath{\mathbf{#1}}}
\renewcommand{\Pr}[1]{\ensuremath{\mathrm{Pr}\left(#1\right)}}
\newcommand{\Exp}[1]{\ensuremath{\mathbb{E}\left[#1\right]}}
\newcommand{\indic}[1]{\ensuremath{\mathbf{1}\left[#1\right]}}
\newcommand{\code}[1]{\texttt{#1}\xspace}

% Heading arguments are {volume}{year}{pages}{submitted}{published}{author-full-names}

\jmlrheading{18}{2017}{1--5}{7/17}{}{}{Benjamin I. P. Rubinstein and Francesco Ald\`{a}}

% Short headings should be running head and authors last names

\ShortHeadings{\pckPlain: An R Package for Practical Differential Privacy}{Rubinstein and Ald\`{a}}
\firstpageno{1}

\begin{document}
%%\SweaveOpts{concordance=TRUE}

\title{\pckPlain: An R Package for Practical Differential Privacy}

\author{\name Benjamin I. P. Rubinstein \email brubinstein@unimelb.edu.au \\
       \addr School of Computing and Information Systems\\
       The University of Melbourne,
       Parkville, VIC 3010, Australia
       \AND
       \name Francesco Ald\`{a} \email francesco.alda@rub.de \\
       \addr Horst G\"ortz Institute for IT Security and Faculty of Mathematics\\
       Ruhr-Universit\"at Bochum,
       D-44780 Bochum, Germany}

\editor{TBD}

\maketitle

\begin{abstract}%   <- trailing '%' for backward compatibility of .sty file
The \R package \pck provides tools for statistics and machine
learning under differential privacy. Suitable for releasing analyses
on privacy-sensitive data to (untrusted) third parties, differential
privacy has become the framework of choice for privacy-preserving
learning. \pck delivers: (a) implementations of popular generic
mechanisms for privatizing non-private target functions, including the
Laplace and exponential mechanisms; (b) a recent sensitivity sampler
due to \citet{rubinstein2017sampler} that empirically estimates the
sensitivity of non-private targets---obviating mathematical analysis for
exact sensitivity bounds needed for most generic mechanisms; (c) an
extensible framework for implementing differentially-private mechanism.
Together, the components of \pck permit easy high-utility privatization
of complex analyses, learners and even black-box software programs.
\end{abstract}

\begin{keywords}
differential privacy, empirical process theory, R, open-source software
\end{keywords}

\section{Introduction}

<<knitr_options, include=FALSE>>=
library(knitr)
opts_chunk$set(fig.width=12, fig.height=4, fig.path='', comment="#>",
               warning=FALSE, message=FALSE, tidy=FALSE, size="small")
options(width=60)
set.seed(53079239)
# install package if necessary:
#if(!require("qtl")) install.packages("qtl", repos="http://cran.us.r-project.org")
@

Differential privacy~\citep{dwork2006calibrating} has quickly become a
key framework for semantic guarantees of data privacy when releasing
analysis on privacy-sensitive data to untrusted third parties.
A great deal of its popularity is owed to a suite of generic mechanisms
for privatizing non-private target functions of data \ie statistics,
estimation procedures, and learners. Common to these generic mechanisms
is the requirement that the non-private target's sensitivity to dataset
perturbation is known and bounded. In all except the most trivial
analyses, bounding sensitivity is prohibitively involved. This paper
describes the \pck \R package that implements generic
mechanisms for differential privacy, along with our recent sensitivity
sampler that replaces exact sensitivity bounds with empirical
estimates~\citep{rubinstein2017sampler}. As a result, \pck enables most
any procedure to be privatized under random differential
privacy~\citep{hall2012random}, without any mathematical analysis and
in many cases high utility.

\section{Generic Mechanisms for Differential Privacy}
\label{sec:generic}

Fundamental to differential privacy is a privacy-sensitive
\term{dataset} (or \term{database}) $D\in\cD^n$ on \term{domain} \cD.
In \pck a dataset can be any \texttt{list}, \texttt{matrix},
\texttt{data.frame}, \texttt{vector}. We say that a pair of
databases $D,D'\in\cD^n$ is \term{neighboring} if they differ on
exactly one record. While individual records of a \cD should not
be revealed, we aim to privately release aggregate information
on \cD with mechanisms. A \term{mechanism} is a random-valued
function of databases, $M: \cD \to \cR$, taking values in a response set;
and implemented in \pck as a virtual class \code{DPMech}.
$M$ preserves differential privacy if its response distributions are close
on neighboring pairs---an adversarial observer of the mechanism, would not
be able to determine a record, even with knowledge of the other $n-1$
records. For more on differential privacy, see the
book~\citep{dwork2014algorithmic}.

\begin{definition}[\citealp{dwork2006calibrating}]
For $\epsilon>0$, mechanism $M: \cD^n \to \cR$ preserves
\term{$\epsilon$-differential privacy} if for all neighboring pairs
$D,D'\in\cD^n$, measurable responses $R\subseteq\cR$, $\Pr{M(D)\in R}\leq \exp(\epsilon)\cdot\Pr{M(D')\in R}$. Alternatively for $\delta\in[0,1)$, relaxed
\term{$(\epsilon,\delta)$-differential privacy} holds if
$\Pr{M(D)\in R}\leq \exp(\epsilon)\cdot\Pr{M(D')\in R}+\delta$.
\end{definition}

Privacy parameters $\epsilon$ ($\epsilon,\delta$) are encapsulated in
instances of \pck classe \code{DPParamsEps} (\code{DPParamsDel}
respectively). As most mechanisms operate at tunable privacy levels,
the virtual\code{DPMech} generic method
\texttt{releaseResponse(mechanism, privacyParams, X)} takes such
privacy parameters along with sensitive dataset.
Most generic mechanisms in differential privacy share a number of properties leveraged by the \pck package as follows.

\paragraph{Privatizing a target function.} Many mechanisms $M: \cD^n\to\cR$
seek to privatize a non-private \term{target} function $f: \cD^n\to\cB$,
with range \cB often (but not always!) coinciding with \cR. As such
all objects of \code{DPMech} mechanisms can be initialized with a
\code{target} slot that holds a variable of type \code{function}. A
mechanism's \code{releaseResponse()} method should call \code{target}
in forming privacy-preserving responses.

\paragraph{Normed target range space.} Target $f$'s output space \cB
is typically imbued with a norm, denoted $\|\cdot\|_{\cB}$, needed
for measuring the sensitivity of $f$'s outputs to input perturbation. \pck flexibly
represents this norm within \code{DPMech} objects as described next.

\paragraph{Sensitivity-induced privacy.} Many mechanisms achieve differential
privacy by calibrating randomization to the sensitivity of the target function
$f$. Targets that are relatively insensitive (sensitive) to perturbing
input $D$ to neighboring $D'$ need relatively little (large) response
randomization. On a pair of neighboring databases $D,D'\in\cD^n$ the
\term{sensitivity} of $f$ is measured as $\Delta(D,D')= \|f(D) - f(D')\|_{\cB}$.
\term{Global sensitivity} is the largest such value
$\overline{\Delta}=\sup_{D,D'}\|f(D)=f(D')\|_{\cB}$ over all possible
neighboring pairs.

As we discuss in \citep{rubinstein2017sampler}, a broad class of generic
mechanisms, taking sensitivity $\Delta$ as a parameter, are
\term{sensitivity-induced private}: for any neighboring pair $D,D'\in\cD^n$ if
$\Delta(D,D')\leq\Delta$ then the mechanism $M_{\Delta}$ run with parameter
$\Delta$ achieves
$\Pr{M_{\Delta}(D)\in R}\leq\exp(\epsilon)\cdot\Pr{M_{\Delta}(D')\in R}$
for all $R\subseteq\cR$. When run with $\Delta=\overline{\Delta}$,
the RHS condition holds for all neighboring pairs, and $M_{\overline{\Delta}}$
satisfies $\epsilon$-differential privacy. Similarly for
$(\epsilon,\delta)$-differential privacy. Indeed this is how all proofs of
differential privacy are derived, for the generic mechanisms implemented in \pck.
\code{DPMech} objects can take a \code{sensitivity} argument at initialization
stored in the slot of the same name. If the user provides a manually-derived
global sensitivity bound $\overline{\Delta}$, then \code{releaseResponse()}
responses preserve $\epsilon$- or ($\epsilon,\delta$)-privacy (depending on
the specific mechanism). This use case is demonstrated by example
next.

\paragraph{Example: Laplace mechanism.}
\pck implements Laplace~\citep{dwork2006calibrating} and
exponential~\citep{mcsherry2007mechanism} mechanisms as \code{DPMech} subclasses
\code{DPMechLaplace} and \code{DPMechExponential}. An exponential example is given
in the next section. The Laplace mechanism requires
that \cB be numeric $\reals^d$ for some $d$, uses $\|\cdot\|_{\cB}$ as the
$L_1$ norm (sum of absolutes). The mechanism releases vectors in the same space
$\cR=\cB$ by adding an i.i.d. sample of $d$ Laplace-dstributed random variables
with means 0 and scale $\overline{\Delta}/\epsilon$ to $f(D)$ to achieve
$\epsilon$-differential privacy. \code{DPMechLaplace} is appropriate for
releasing numeric vectors.

We next demonstrate Laplace privatization of the sample mean on
bounded data in $\cD^n=[0,1]^n$, for which \cB dimension is one. Global
sensitivity is readily bounded as $1/n$: For any
neighboring pair $D,D'\in[0,1]^n$,
$\Delta(D,D')=n^{-1}\left|\sum_{i=1}^n D_i - \sum_{i=1}^n D'_i\right|$. And
since $n-1$ records are the same and the records are in $[0,1]$, this is
$|D_n - D'_n|/n \leq 1/n$.

<<genericLaplace, include=TRUE, echo=TRUE, results='markup'>>=
library(diffpriv)
f <- function(X) mean(X) ## target function
n <- 100 ## dataset size
mechanism <- DPMechLaplace(target = f, sensitivity = 1/n, dim = 1)
D <- runif(n, min = 0, max = 1) ## the sensitive database in [0,1]^n
pparams <- DPParamsEps(epsilon = 1) ## desired privacy budget
r <- releaseResponse(mechanism, privacyParams = pparams, X = D)
cat("Private response r$response:",   r$response,
    "\nNon-private response f(D):  ", f(D))
@

\vspace{-1em}

\section{Sensitivity Sampling for Random Differential Privacy}
\label{sec:sampler}

When \code{target} global sensitivity is supplied as \code{sensitivity} within
\code{DPMech} construction, responses are differentially private.
Global sensitivity has been calculated for
idealizations of \eg coefficients for regularized logistic
regression~\citep{chaudhuri2009logistic} and the support vector
machine~\citep{rubinstein2012svm,chaudhuri2011erm}. In complex applications
such as privatizing a software function, however, \code{target}'s global
sensitivity may not be readily available. For such cases, \pck implements the
sensitivity sampler of \citet{rubinstein2017sampler} which forms a
high-probability estimate of target sensitivity by repeated probing of sensitivity
on random neighboring database pairs, leveraging tools from empirical process
theory. Like sensitivity estimates, privacy holds with high probability.

\begin{definition}[\citealp{hall2012random}]
A mechanism $M$ preserves \term{$(\epsilon,\gamma)$-random differential privacy}
(with a corresponding form for $\epsilon,\delta,\gamma$) if
$\forall R\subseteq\cR, \Pr{M(D)\in R}\leq\exp(\epsilon)\cdot\Pr{M(D')\in R}$ holds
with probability at least $1-\gamma$ over random database pairs $D,D'$.
\end{definition}

While weaker than $\epsilon$-DP, RDP is arguably more natural than
$(\epsilon,\delta)$-DP: The later safeguards all databases but not
unlikely responses, while RDP protections against all responses but not
pathological databases (as defined by the database sampling distribution). The
sampling distribution can be anything meaningful \eg uniform, a Bayesian prior,
a density from data privately fit by the Bernstein
mechanism~\citep{alda2017bernstein}, etc.

The \code{DPMech} method \code{sensitivitySampler(object, oracle, n, m, gamma)}
requires a mechanism \code{object}, a function \code{oracle} which
outputs i.i.d. random databases of given size, the size of input database \code{n}
supplied later in calls to \code{releaseResponse()}, a sensitivity sample size
\code{m}, and desired privacy confidence \code{gamma}. Either (but not both) of
\code{m}, \code{gamma} can be ommitted: the ommitted resource will be optimized
automatically. For example \code{m} taken small (few hundred) can be used given
limited time for sampling; small given \code{gamma} (\eg 0.05) prioritizes privacy.
The sensitivity sampler calls \code{DPMech} method \code{sensitivityNorm()} which
implements $\Delta(D,D')$ for the mechanism's norm and stored \code{target}. New
sublcasses of \code{DPMech} need only implement this method in
order to take advantage of the sensitivity sampler. Following
\code{sensitivitySampler()}, subsequent \code{releaseResponse()} results have
a privacy parameter slot of type \code{DPParamsGam} indicating response RDP.

\paragraph{Example: Exponential mechanism.} Any sensitivity-induced \code{DPMech}
(\eg Laplace) can be sensitivity sampled; we demonstrate the
exponential mechanism here. Exponential privately optimizes an
application-specific objective (or score, utility) function $s(r)$ of candidate
response $r\in\cR$, with response distribution proportional to
$\exp(\epsilon \cdot s(r) / (2\Delta))$. Typically $s$ is implicitly dependent on
input $D$, and so \code{DPMechExponential} is initialized with \code{target}
that takes $D$ and outputs a score function. That is, $\cB=\reals^{\cR}$ is a
real-valued function space on \cR and the class's \code{sensitivityNorm()}
implements the sup-norm (\cf \citealp{rubinstein2017sampler}). In practice,
users supply \code{target} as an \R closure as demonstrated below. Given
global \code{sensitivity} of \code{target}, the mechanism preserves $\epsilon$-DP;
if \code{sensitivitySampler()} estimates sensitivity with some \code{gamma},
then RDP is preserved at confidence $\gamma=$\code{gamma}.

Applying these ideas to find the most frequent a--z character within a
dataset of top-10 computer scientists from Semantic Scholar, subject to privacy of
individuals. The exponential mechanism privately maximizes total frequency. But
Without bounded name lengths, this function has unbounded global sensitivity. The
sensitivity sampler is therefore used for $(1,0.1)$-RDP, with an oracle that samples
representative U.S. names based on \code{randomNames}.

<<samplerExponential, include=TRUE, echo=TRUE, results='markup'>>=
library(randomNames)
oracle <- function(n) randomNames(n)
D <- c("Michael Jordan", "Andrew Ng", "Andrew Zisserman","Christopher Manning",
       "Jitendra Malik", "Geoffrey Hinton", "Scott Shenker",
       "Bernhard Scholkopf", "Jon Kleinberg", "Judea Pearl")
n <- length(D)
f <- function(X) { function(r) sum(r == unlist(base::strsplit(X, ""))) }
rSet <- as.list(letters) ## the response set, letters a--z
mechanism <- DPMechExponential(target = f, responseSet = rSet)
mechanism <- sensitivitySampler(mechanism, oracle = oracle, n = n, gamma = 0.1)
pparams <- DPParamsEps(epsilon = 1)
r <- releaseResponse(mechanism, privacyParams = pparams, X = D)
cat("Private response r$response: ",   r$response,
    "\nNon-private f(D) maximizer:  ", letters[which.max(sapply(rSet, f(D)))])
@

\vspace{-2em}

%Since mechanisms, notably Laplace and exponential, tend to use the norm $\|\cdot\|_{\cB}$ only for computing sensitivity $\Delta(D,D')$, and tend to assume one particular norm, \pck represents a minimal interface to the norm via \code{DPMech} method \code{sensitivityNorm()}. In implemented generic mechanisms that require a fixed norm, this norm is built into the corresponding method. For (future) user-defined mechanisms, function-dependent norms can also be supplied at initialization by extended the class constructor.

%pressure phenotype, will consider just the \Sexpr{1+2} individuals with

%%<<summary_cross, fig.height=8>>=
%%hist(rnorm(100))
%%@

%\section{R and package versions used}
%
%<<sessionInfo, include=TRUE, echo=TRUE, results='markup'>>=
%sessionInfo()
%@

% Acknowledgements should go at the end, before appendices and references

\acks{B. Rubinstein and F. Ald\`a acknowledge the support
of the Australian Research Council (DE160100584) and the
DFG Research Training Group GRK 1817/1 respectively.}

\vskip 0.2in
\bibliography{diffpriv}

\end{document}
