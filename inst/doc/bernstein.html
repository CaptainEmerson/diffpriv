<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="The diffpriv team" />

<meta name="date" content="2017-07-14" />

<title>The Bernstein mechanism</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">The Bernstein mechanism</h1>
<h4 class="author"><em>The diffpriv team</em></h4>
<h4 class="date"><em>2017-07-14</em></h4>



<p>This vignette presents a short tutorial on the application of the generic Bernstein mechanism <code>DPMechBernstein</code> for differentially-private release of functions in the <code>diffpriv</code> R package.</p>
<p>The primary use case of the Bernstein mechanism is releasing real-valued functions on <span class="math inline">\([0,1]^d\)</span>. The typical function released will depend on an arbitrary sensitive dataset (which could be numeric or otherwise), and after release the function may be evaluated on unlimited points.</p>
<p>If you make use of the mechanism in your work, please consider citing the <a href="https://arxiv.org/abs/1507.04499">original paper</a> in any subsequent writeup:</p>
<blockquote>
<p>Francesco Aldà and Benjamin I. P. Rubinstein. “The Bernstein Mechanism: Function Release under Differential Privacy”, in Proceedings of the 31st AAAI Conference on Artificial Intelligence (AAAI’2017), pp. 1705-1711, 2017.</p>
</blockquote>
<div id="bernstein-polynomial-approximation" class="section level2">
<h2>Bernstein Polynomial Approximation</h2>
<p>Like the more common Taylor polynomial approximation, Bernstein approximations of a target function <span class="math inline">\(f:[0,1]^d \to \mathbb{R}\)</span> involve a weighted sum of basis polynomials. We’ll refer to these weights as coefficients, and introduce the Bernstein approximation for the simple one-dimensional <span class="math inline">\(d=1\)</span> case. For details on the multidimensional case (implemented in <code>diffpriv</code> see the reference paper above).</p>
<p>The <span class="math inline">\(k+1\)</span> Bernstein basis polynomials of degree <span class="math inline">\(k\)</span> are defined as <span class="math inline">\(b_{\nu, k}(x)={k \choose \nu} x^\nu (1-x)^{k-\nu}\)</span> for <span class="math inline">\(\nu\)</span> ranging over <span class="math inline">\(0, \ldots, k\)</span>. Fixing <span class="math inline">\(\nu\)</span> and for varying <span class="math inline">\(x\in[0,1]\)</span>, the basis function corresponds to the probability that <span class="math inline">\(k\)</span> coin tosses results in <span class="math inline">\(\nu\)</span> heads, where the chance of a head is <span class="math inline">\(x\)</span>. Taken as a whole, the set of basis functions therefore makes up the entire probability mass for the <span class="math inline">\(Binomial(k,x)\)</span> distribution.</p>
<p>The coefficients of the Bernstein approximation of target <span class="math inline">\(f\)</span> are simply the evaluations of <span class="math inline">\(f\)</span> on the <span class="math inline">\((k+1)\)</span>-point regular grid covering <span class="math inline">\([0,1]\)</span>: at points <span class="math inline">\(\{0, 1/k, \ldots, k/k\}\)</span>.</p>
<p>Together, then, <span class="math inline">\(f(x)\)</span> is approximated as <span class="math inline">\(\tilde{f}(x)=\sum_{\nu=0}^k f(\nu/k) b_{\nu,k}(x)\)</span> which can be interpreted as the expectation of <span class="math inline">\(f(X/k)\)</span> for <span class="math inline">\(X\sim Binomial(k, x)\)</span>. We note in passing that nice guarantees exist about the closeness of <span class="math inline">\(\tilde{f}\)</span> to <span class="math inline">\(f\)</span>, with natural conditions on smoothness of <span class="math inline">\(f\)</span>.</p>
<div id="example" class="section level3">
<h3>Example</h3>
<p>To see Bernstein approximation in action in <code>diffpriv</code>, consider approximating the function <span class="math inline">\(f(x) = x \sin(10 x)\)</span> on <span class="math inline">\(x\in[0,1]\)</span> with a Bernstein polynomial of degree <span class="math inline">\(k=25\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(diffpriv)
targetF &lt;-<span class="st"> </span>function(x) x *<span class="st"> </span><span class="kw">sin</span>(<span class="dv">10</span> *<span class="st"> </span>x)
bernsteinF &lt;-<span class="st"> </span><span class="kw">bernstein</span>(targetF, <span class="dt">dims =</span> <span class="dv">1</span>, <span class="dt">k =</span> <span class="dv">25</span>)</code></pre></div>
<p>The returned value is an <code>S3</code> object of class <code>bernstein</code>, a list with various slots including one that holds the <span class="math inline">\(k+1\)</span> coefficients of the approximation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bernsteinF$coeffs
<span class="co">#&gt;  [1]  0.00000000  0.01557673  0.05738849  0.11184469  0.15993178</span>
<span class="co">#&gt;  [6]  0.18185949  0.16211116  0.09379668 -0.01867973 -0.15930736</span>
<span class="co">#&gt; [11] -0.30272100 -0.41870491 -0.47815901 -0.45939642 -0.35350932</span>
<span class="co">#&gt; [16] -0.16764930  0.07459149  0.33599708  0.57144086  0.73561895</span>
<span class="co">#&gt; [21]  0.79148660  0.71786308  0.51472713  0.20505872 -0.16735371</span>
<span class="co">#&gt; [26] -0.54402111</span></code></pre></div>
<p>Predictions <span class="math inline">\(\tilde{f}(x)\)</span> can be made for objects of type <code>bernstein</code> using the <code>predict.bernstein()</code> function implementing the <code>S3</code> generic <code>predict()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(bernsteinF, <span class="dt">D =</span> <span class="fl">0.2</span>)   <span class="co"># approximate f(0.5)</span>
<span class="co">#&gt; [1] 0.1101786</span>
<span class="kw">targetF</span>(<span class="fl">0.2</span>)                   <span class="co"># actual f(0.5)</span>
<span class="co">#&gt; [1] 0.1818595</span></code></pre></div>
<p>Evaluation on a collection of points is also easy.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">xs &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">1</span>, <span class="dt">length =</span> <span class="dv">50</span>)
<span class="kw">plot</span>(xs, <span class="kw">targetF</span>(xs), <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">ylim =</span> <span class="kw">c</span>(-<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">lty =</span> <span class="st">&quot;dashed&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>,
     <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;x&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;y&quot;</span>,
     <span class="dt">main=</span><span class="st">&quot;Bernstein polynomial approximation&quot;</span>)
<span class="kw">lines</span>(xs, <span class="kw">predict</span>(bernsteinF, xs), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</code></pre></div>
<div class="figure">
<img src="data:image/png;base64,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" alt="Bernstein polynomial approximation (blue) vs target (red)." />
<p class="caption">Bernstein polynomial approximation (blue) vs target (red).</p>
</div>
</div>
</div>
<div id="differential-privacy-with-the-bernstein-mechanism" class="section level2">
<h2>Differential Privacy with the Bernstein Mechanism</h2>
<p>The <code>S4</code> class <code>DPMechBernstein</code> subclasses the virtual <code>DPMech</code> within the <code>diffpriv</code> package, implementing the generic Bernstein mechanism. The mechanism</p>
<ul>
<li>First instantiates the target function, itself a function of sensitive input data (such as a classifier or statistical model).</li>
<li>It then forms a Bernstein polynomial approximation as described above.</li>
<li>The Laplace mechanism <code>DPMechLaplace</code> is used to perturb the Bernstein approximation coefficients. As these are the only component of the approximation that depends on the target function (and hence input dataset; the basis polynomials are target/data-independent), this is sufficient for preserving differential privacy.</li>
<li>Subsequent evaluations of the perturbed approximation function are simply sums of the basis polynomials, weighted by these perturbed coefficients.</li>
</ul>
<p>A sufficient level of Laplace noise depends on the global sensitivity of the target function, required as an argument to <code>DPMechBernstein</code> construction unless the sensitivity sampler is used (demonstrated in the example below). Intuitively, targets that are more volatile—vary more with perturbed input data—require more smoothing by Laplace noise.</p>
<div id="example-1" class="section level3">
<h3>Example</h3>
<p>Suppose we want to fit a sensitive dataset <code>D</code> with Priestly-Chao kernel regression, using the Gaussian kernel with a <code>bandwidth</code> hyperparameter specifying kernel smoothness. For simplicity, we’ll consider a single co-variate. A fitting function for the estimator is given as follows. It takes <code>D</code> a 2-column matrix with examples in rows, and returns a function for making predictions on new data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pck_regression &lt;-<span class="st"> </span>function(D, <span class="dt">bandwidth =</span> <span class="fl">0.1</span>) {
  K &lt;-<span class="st"> </span>function(x) <span class="kw">exp</span>(-x^<span class="dv">2</span>/<span class="dv">2</span>)
  ids &lt;-<span class="st"> </span><span class="kw">sort</span>(D[,<span class="dv">1</span>], <span class="dt">decreasing =</span> <span class="ot">FALSE</span>, <span class="dt">index.return =</span> <span class="ot">TRUE</span>)$ix
  D &lt;-<span class="st"> </span>D[ids, ]
  n &lt;-<span class="st"> </span><span class="kw">nrow</span>(D)
  ws &lt;-<span class="st"> </span>(D[<span class="dv">2</span>:n,<span class="dv">1</span>] -<span class="st"> </span>D[<span class="dv">1</span>:(n<span class="dv">-1</span>),<span class="dv">1</span>]) *<span class="st"> </span>D[<span class="dv">2</span>:n,<span class="dv">2</span>]
  predictor &lt;-<span class="st"> </span>function(x) {
    <span class="kw">sum</span>(ws *<span class="st"> </span><span class="kw">sapply</span>((x -<span class="st"> </span>D[<span class="dv">2</span>:n,<span class="dv">1</span>]) /<span class="st"> </span>bandwidth, K)) /<span class="st"> </span>bandwidth
  }
  <span class="kw">return</span>(predictor)
}</code></pre></div>
<p>We have the following (synthetic) sensitive dataset, as a <span class="math inline">\(250\times 2\)</span> matrix with the first column representing co-variates/features and the second column representing dependent variables/labels.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">N &lt;-<span class="st"> </span><span class="dv">250</span>
D &lt;-<span class="st"> </span><span class="kw">runif</span>(N)
D &lt;-<span class="st"> </span><span class="kw">cbind</span>(D, <span class="kw">sin</span>(D*<span class="dv">10</span>)*D +<span class="st"> </span><span class="kw">rnorm</span>(N, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="fl">0.2</span>))</code></pre></div>
<p>Let’s fit three models for comparison:</p>
<ul>
<li>A non-private exact Priestly-Chao regression given by <code>model</code>;</li>
<li>A non-private Bernstein approximation of the exact regression <code>bmodel</code>; and</li>
<li>A privatized regression produced by <code>DPMechBernstein</code>, <code>pmodel</code>.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Non private fitting
model &lt;-<span class="st"> </span><span class="kw">pck_regression</span>(D)

## Bernstein non private fitting
K &lt;-<span class="st"> </span><span class="dv">25</span>
bmodel &lt;-<span class="st"> </span><span class="kw">bernstein</span>(model, <span class="dt">dims=</span><span class="dv">1</span>, <span class="dt">k=</span>K)

## Private Bernstein fitting
m &lt;-<span class="st"> </span><span class="kw">DPMechBernstein</span>(<span class="dt">target=</span>pck_regression, <span class="dt">latticeK=</span>K, <span class="dt">dims=</span><span class="dv">1</span>)
P &lt;-<span class="st"> </span>function(n) {  <span class="co"># a sampler of random, &quot;plausible&quot;, datasets</span>
  Dx &lt;-<span class="st"> </span><span class="kw">runif</span>(n)
  Dy &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, n)
  if (<span class="kw">runif</span>(<span class="dv">1</span>) &lt;<span class="st"> </span><span class="fl">0.95</span>) Dy &lt;-<span class="st"> </span>Dy +<span class="st"> </span>Dx
  if (<span class="kw">runif</span>(<span class="dv">1</span>) &lt;<span class="st"> </span><span class="fl">0.5</span>) Dy &lt;-<span class="st"> </span>Dy *<span class="st"> </span><span class="kw">sin</span>(Dx)
  if (<span class="kw">runif</span>(<span class="dv">1</span>) &lt;<span class="st"> </span><span class="fl">0.5</span>) Dy &lt;-<span class="st"> </span>Dy *<span class="st"> </span><span class="kw">cos</span>(Dx)
  <span class="kw">cbind</span>(Dx, Dy +<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="fl">0.2</span>))
}
m &lt;-<span class="st"> </span><span class="kw">sensitivitySampler</span>(m, <span class="dt">oracle=</span>P, <span class="dt">n=</span>N, <span class="dt">gamma=</span><span class="fl">0.20</span>, <span class="dt">m=</span><span class="dv">500</span>)
<span class="co">#&gt; Sampling sensitivity with m=500 gamma=0.2 k=439</span>
R &lt;-<span class="st"> </span><span class="kw">releaseResponse</span>(m, <span class="dt">privacyParams=</span><span class="kw">DPParamsEps</span>(<span class="dt">epsilon=</span><span class="dv">5</span>), <span class="dt">X=</span>D)
pmodel &lt;-<span class="st"> </span>R$response</code></pre></div>
<p>The private model is produced as described above. <code>sensitivitySampler()</code> probes the non-private model with <span class="math inline">\(500\)</span> random pairs of datasets, sampled from <code>P()</code>, to estimate the target’s sensitivity. The resulting perturbed private model preserves random differential privacy with level <span class="math inline">\(\epsilon=5\)</span> and confidence <span class="math inline">\(\gamma=0.2\)</span>. In practice we could easily take <span class="math inline">\(\gamma\)</span> much smaller (much higher confidence) by increasing sensitivity sample size <code>m</code>.</p>
<p>Let’s now take our three fitted models, and predict the dependent variable/label across a range of covariates/features.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">xs &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from=</span><span class="dv">0</span>, <span class="dt">to=</span><span class="dv">1</span>, <span class="dt">length=</span><span class="dv">50</span>)
yhats   &lt;-<span class="st"> </span><span class="kw">sapply</span>(xs, model)
yhats.b &lt;-<span class="st"> </span><span class="kw">predict</span>(bmodel, xs)
yhats.p &lt;-<span class="st"> </span>R$<span class="kw">response</span>(xs)</code></pre></div>
<p>We can now finally visually compare the three fitted models, alongside the original training dataset.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">xlim &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)
ylim &lt;-<span class="st"> </span><span class="kw">range</span>(<span class="kw">c</span>(yhats.b, yhats.p, yhats, D[,<span class="dv">2</span>]))
<span class="kw">plot</span>(D, <span class="dt">pch=</span><span class="dv">20</span>, <span class="dt">cex=</span><span class="fl">0.8</span>, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">ylim=</span>ylim, <span class="dt">xlab=</span><span class="st">&quot;X&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Y&quot;</span>,
    <span class="dt">main=</span><span class="st">&quot;Priestly-Chao Kernel Regression&quot;</span>, <span class="dt">col=</span><span class="st">&quot;grey&quot;</span>)
<span class="kw">lines</span>(xs, yhats.p, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>,  <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">lty=</span><span class="st">&quot;solid&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)
<span class="kw">lines</span>(xs, yhats.b, <span class="dt">col=</span><span class="st">&quot;green&quot;</span>, <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">lty=</span><span class="st">&quot;dotted&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)
<span class="kw">lines</span>(xs, yhats,   <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,   <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">lty=</span><span class="st">&quot;dashed&quot;</span>, <span class="dt">lwd =</span><span class="dv">2</span>)</code></pre></div>
<div class="figure">
<img src="data:image/png;base64,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" alt="Kernel regression on 1D training data (points): non-private model (red dashed); non-private Bernstein polynomial approximation (green dotted); private Bernstein mechanism (blue solid)." />
<p class="caption">Kernel regression on 1D training data (points): non-private model (red dashed); non-private Bernstein polynomial approximation (green dotted); private Bernstein mechanism (blue solid).</p>
</div>
<p>We could safely release the model <code>pmodel</code> but not the other non-private models. Also note that while a target’s sensitivity can be computed/bounded manually in many cases, when the target is more complex sensitivity analysis can be prohibative. The sensitivity sampler offers a pragmatic approach to such situations, replacing exact bounds with random probing and estimation. For the resulting random differential privacy to make sense, the sampling distribution (passed as argument <code>oracle</code> to the sensitivity sampler) should reflect public knowledge about the dataset. This could be noninformative (like a uniform/normal distribution), it could be a public Bayesian prior, it could even be the result of density estimation on a real dataset (potentially privately estimated).</p>
<p>If using the sensitivity sampler, we suggest citing the original paper:</p>
<blockquote>
<p>Benjamin I. P. Rubinstein and Francesco Aldà. “Pain-Free Random Differential Privacy with Sensitivity Sampling”, to appear in the 34th International Conference on Machine Learning (ICML’2017), 2017.</p>
</blockquote>
<p>Further details on the sampler can be found there.</p>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
